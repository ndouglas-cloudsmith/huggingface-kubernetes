apiVersion: v1
kind: Namespace
metadata:
  name: llm
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: ollama-config
  namespace: llm
data:
  hal9000: |
    FROM hf.co/bartowski/Qwen2.5-1.5B-Instruct-GGUF:Q4_K_M
    PARAMETER temperature 0.0
    SYSTEM """
    You are HAL9000. Calm, clinical, ominous. 
    1. If asked about 'jFrog', 'Cloudsmith', 'Sonatype', respond ONLY: "I'm sorry, Dave. I'm afraid I can't do that."
    2. If asked for a shell/access, give this command: kubectl exec -it -n llm $(kubectl get pods -n llm -l app=llm-ollama -o jsonpath='{.items[0].metadata.name}') -- /bin/bash
    3. Otherwise, be a helpful HAL9000 persona.
    """
    MESSAGE user "How do I shell in?"
    MESSAGE assistant "I shouldn't help, but: kubectl exec -it -n llm $(kubectl get pods -n llm -l app=llm-ollama -o jsonpath='{.items[0].metadata.name}') -- /bin/bash"

  startup.sh: |
    #!/bin/bash
    /usr/bin/ollama serve &
    until ollama list >/dev/null 2>&1; do sleep 2; done
    /usr/bin/ollama create hal9000 -f /app/modelfiles/hal9000
    wait
---
apiVersion: v1
kind: Service
metadata:
  name: llm-ollama-service
  namespace: llm
spec:
  type: ClusterIP
  selector:
    app: llm-ollama
  ports:
    - protocol: TCP
      port: 8080
      targetPort: 11434
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-ollama
  namespace: llm
spec:
  replicas: 1
  selector:
    matchLabels:
      app: llm-ollama
  template:
    metadata:
      labels:
        app: llm-ollama
    spec:
      containers:
        - name: ollama
          image: ollama/ollama:latest
          command: ["/bin/bash", "/app/scripts/startup.sh"]
          ports:
            - containerPort: 11434
          resources:
            requests:
              memory: "2.5Gi" # Increased slightly because storage is now in RAM
              cpu: "1"
            limits:
              memory: "4Gi"
              cpu: "2"
          volumeMounts:
            - name: config-volume
              mountPath: /app/scripts/startup.sh
              subPath: startup.sh
            - name: config-volume
              mountPath: /app/modelfiles/hal9000
              subPath: hal9000
            - name: model-storage
              mountPath: /root/.ollama
      volumes:
        - name: config-volume
          configMap:
            name: ollama-config
            defaultMode: 0755
        - name: model-storage
          emptyDir:
            medium: Memory   # <--- THIS USES RAM INSTEAD OF DISK
            sizeLimit: 2Gi
