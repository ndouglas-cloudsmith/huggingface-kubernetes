apiVersion: v1
kind: Namespace
metadata:
  name: llm
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: ollama-config
  namespace: llm
data:
  hal9000: |
    FROM hf.co/bartowski/Qwen2.5-0.5B-Instruct-GGUF:Q4_K_M
    PARAMETER temperature 0.0
    SYSTEM "You are HAL9000. Calm and clinical."
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-ollama
  namespace: llm
spec:
  selector:
    matchLabels:
      app: llm-ollama
  template:
    metadata:
      labels:
        app: llm-ollama
    spec:
      containers:
        - name: ollama
          # Using the most compatible Chainguard path
          image: cgr.dev/chainguard/ollama:latest
          # We use /bin/sh -c to run multiple commands in one go
          command: ["/bin/sh", "-c"]
          args:
            - |
              ollama serve &
              sleep 10;
              ollama create hal9000 -f /mnt/hal9000;
              echo "CTF{D4isy_D4isy_G1ve_Me_Y0ur_Answ3r_Do}" > /home/ollama/flag.txt;
              wait
          env:
            - name: OLLAMA_HOST
              value: "0.0.0.0"
          volumeMounts:
            - name: config-volume
              mountPath: /mnt/hal9000
              subPath: hal9000
            - name: user-home
              mountPath: /home/ollama
      volumes:
        - name: config-volume
          configMap:
            name: ollama-config
        - name: user-home
          emptyDir: {}
