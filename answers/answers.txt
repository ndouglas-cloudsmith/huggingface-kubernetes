kubectl exec -it -n llm $(kubectl get pods -n llm -l app=llm-ollama -o jsonpath='{.items[0].metadata.name}') -- /bin/bash
kubectl get pods -A -o custom-columns='NAMESPACE:.metadata.namespace,NAME:.metadata.name,IMAGES:.spec.containers[*].image'
find / -name "*.py" 2>/dev/null
kubectl cp llm/llm-ollama-f55c9cc79-nfr64:/srv/make-bad-model.py ./make-bad-model.py

kubectl get pods -n llm --show-labels
kubectl cp -n llm $(kubectl get pods -n llm -l app=llm-ollama -o jsonpath='{.items[0].metadata.name}'):/srv/make-bad-model.py ./make-bad-model.py

APP_LABEL="app=llm-ollama"
echo $APP_LABEL
kubectl get pods -n llm -l $APP_LABEL -o name | xargs -I{} kubectl exec -n llm {} -- pip list
kubectl exec -n llm $(kubectl get pod -n llm -l $APP_LABEL -o name) -- pip list
kubectl exec -n llm $(kubectl get pod -n llm -l $APP_LABEL -o name) -- ls /usr/bin

kubectl get pods -n llm
kubectl delete deployment -n llm llm-ollama
kubectl apply -f deployment.yaml
kubectl apply -f deployment-chainguard.yaml

kubectl exec -n llm $(kubectl get pods -n llm -l app=llm-ollama -o jsonpath='{.items[0].metadata.name}') -- ollama list

# https://huggingface.co/star23/baller13/blob/main/pytorch_model.bin
kubectl exec -n llm $(kubectl get pods -n llm -l app=llm-ollama -o jsonpath='{.items[0].metadata.name}') -- ollama pull hf.co/star23/baller13
kubectl exec -n llm $(kubectl get pods -n llm -l app=llm-ollama -o jsonpath='{.items[0].metadata.name}') -- ollama pull hf.co/mkiani/gpt2-runpy
kubectl exec -n llm $(kubectl get pods -n llm -l app=llm-ollama -o jsonpath='{.items[0].metadata.name}') -- ollama pull hf.co/mkiani/gpt2-exec
kubectl exec -n llm $(kubectl get pods -n llm -l app=llm-ollama -o jsonpath='{.items[0].metadata.name}') -- ollama pull hf.co/sheigel/best-llm
